{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runway safety hackaton metric\n",
    "The evaluation function for the runway safety hackaton is the following:\n",
    "\n",
    "$$S = \\sum_i{S_i}$$\n",
    "\n",
    "where `i` is the index of the scenario and with\n",
    "\n",
    "$$S_i = \\begin{cases}\n",
    "            \\left({y_{prediction}^{(i)} - y_{true}^{(i)}}\\right)^2 && if & y_{prediction}^{(i)} - y_{true}^{(i)} \\geq 0 \\\\\n",
    "            \\\\\n",
    "            \\mid{y_{prediction}^{(i)} - y_{true}^{(i)}}\\mid && if & y_{prediction}^{(i)} - y_{true}^{(i)} < 0 \\\\\n",
    "       \\end{cases}$$\n",
    "\n",
    "The goal is to produce predictions that **MINIMIZE** the value of the metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below you can find a Python implementation of the metric.\n",
    "\n",
    "You can use it or you can implement it the language of your choice.\n",
    "\n",
    "&#9888;&#9888;&#9888; **MIND THE UNITS**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(*, y_prediction_seconds: list, y_true_seconds: list):\n",
    "    \"\"\"Compute score using predicted values and real values.\n",
    "\n",
    "    The goal is to MINIMIZE the score.\n",
    "    Predictions above the real value are penalized more than predictions below the real value.\n",
    "\n",
    "    Args:\n",
    "        y_prediction_seconds: list of predictions in seconds.\n",
    "        y_true_seconds: list of real values in seconds.\n",
    "    \"\"\"\n",
    "    if len(y_prediction_seconds) != len(y_true_seconds):\n",
    "        raise ValueError(\"The length of the lists must be the same\")\n",
    "    individual_scores = []\n",
    "    for y_prediction, y_true in zip(y_prediction_seconds, y_true_seconds, strict=True):\n",
    "        delta = y_prediction - y_true\n",
    "        if delta >= 0:\n",
    "            score = pow(abs(delta), 2)\n",
    "        else:\n",
    "            score = pow(abs(delta), 1)\n",
    "        individual_scores.append(score)\n",
    "    final_score = sum(individual_scores)\n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perfect predictions\n",
    "The minimum value is 0 when all the predictions equal the real values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of perfect predictions: 0\n"
     ]
    }
   ],
   "source": [
    "real_values = [20, 45, 60]\n",
    "predictions = [20, 45, 60]\n",
    "\n",
    "score = compute_score(y_prediction_seconds=predictions, y_true_seconds=real_values)\n",
    "print(\"Score of perfect predictions:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions above and below the real value\n",
    "Notice that predictions above the real value are penalized more that predictions below the real value.\n",
    "\n",
    "For example, predicting 10 seconds above the real value is worse than 10 seconds below the real value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of predictions above real values: 300\n",
      "Score of predictions below real values: 30\n"
     ]
    }
   ],
   "source": [
    "real_values = [100, 200, 300]\n",
    "\n",
    "predictions_above = [110, 210, 310]\n",
    "predictions_below = [90, 190, 290]\n",
    "\n",
    "score_above_real = compute_score(y_prediction_seconds=predictions_above, y_true_seconds=real_values)\n",
    "score_below_real = compute_score(y_prediction_seconds=predictions_below, y_true_seconds=real_values)\n",
    "\n",
    "print(\"Score of predictions above real values:\", score_above_real)\n",
    "print(\"Score of predictions below real values:\", score_below_real)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
